# Sistema Multi-Agentes para Gera√ß√£o de Conte√∫do

Sistema completo de gera√ß√£o de conte√∫do usando FastAPI, CrewAI, LangChain e Ollama para criar conte√∫do automatizado para m√∫ltiplas plataformas.

## üèóÔ∏è Arquitetura

- **FastAPI**: API REST para orquestra√ß√£o
- **CrewAI**: Framework para agentes especializados
- **LangChain**: Integra√ß√£o com LLMs
- **Ollama**: LLM local (Mistral)
- **ChromaDB**: Vector database para RAG
- **Redis**: Cache e rate limiting
- **Nginx**: Proxy reverso e load balancer
- **Prometheus + Grafana**: Monitoramento

## üöÄ Deploy R√°pido

### Pr√©-requisitos
- Docker e Docker Compose
- 8GB+ RAM (recomendado para Ollama)
- Portas dispon√≠veis: 80, 8000, 11434, 6379, 9090, 3000

### Inicializa√ß√£o

```bash
# clona o reposit√≥rio
git clone <seu-repo>
cd multi_agentes_conte√∫do

# copia configura√ß√µes
cp .env.example .env

# edita vari√°veis se necess√°rio
nano .env

# inicia todos os servi√ßos
docker-compose up -d

# verifica status
docker-compose ps
```

### Primeira Configura√ß√£o

```bash
# baixa modelo Mistral no Ollama (pode demorar)
docker exec multi_agentes_ollama ollama pull mistral:latest

# verifica se modelo foi baixado
docker exec multi_agentes_ollama ollama list
```

## üìã Endpoints Principais

### Gera√ß√£o de Conte√∫do
```bash
# processa brief completo
POST /api/brief
{
  "topic": "Tend√™ncias de IA em 2024",
  "target_audience": "Profissionais de tecnologia",
  "tonality": "professional",
  "platforms": ["instagram", "linkedin"],
  "duration": 60,
  "additional_context": "Foco em aplica√ß√µes pr√°ticas"
}

# verifica status da tarefa
GET /api/tasks/{task_id}

# responde coment√°rio p√∫blico
POST /api/public/comment
{
  "comment": "Que legal! Tem mais dicas?",
  "context": "Post sobre IA",
  "platform": "instagram"
}
```

### Monitoramento
```bash
# health check
GET /health

# estat√≠sticas da mem√≥ria
GET /api/memory/stats

# m√©tricas do Prometheus
GET /metrics
```

## üîß Configura√ß√£o Avan√ßada

### Vari√°veis de Ambiente (.env)

```bash
# Ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=mistral:latest

# API
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Marca/Persona
BRAND_NAME=Sua Marca
BRAND_PERSONA=Inovadora e pr√≥xima do p√∫blico
BRAND_VALUES=Autenticidade,Inova√ß√£o,Conex√£o

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600
```

### Customiza√ß√£o de Agentes

Edite `agents.py` para ajustar:
- Prompts dos agentes
- Comportamentos espec√≠ficos
- Novos tipos de agente

### Adicionando Guidelines da Marca

```python
from memory import get_memory_manager

memory = get_memory_manager()

# adiciona guideline
memory.store_brand_guideline(
    title="Tom de Voz",
    content="Sempre use linguagem acess√≠vel e evite jarg√µes t√©cnicos...",
    category="voice"
)

# adiciona tend√™ncia
memory.store_trend_insight(
    trend="V√≠deos curtos verticais",
    description="Formato dominante em 2024...",
    platforms=[Platform.INSTAGRAM, Platform.TIKTOK]
)
```

## üìä Monitoramento

### Grafana Dashboards
- **URL**: http://localhost:3000
- **Login**: admin / admin123
- **Dashboards**: M√©tricas da API, performance dos agentes, uso de recursos

### Prometheus Metrics
- **URL**: http://localhost:9090
- **Targets**: API, Nginx, Redis, Ollama

### Logs
```bash
# logs da API
docker logs multi_agentes_api -f

# logs do Ollama
docker logs multi_agentes_ollama -f

# logs de todos os servi√ßos
docker-compose logs -f
```

## üõ†Ô∏è Desenvolvimento

### Ambiente Local
```bash
# instala depend√™ncias
pip install -r requirements.txt

# configura Ollama local
ollama serve
ollama pull mistral:latest

# roda API em desenvolvimento
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Testes
```bash
# testa endpoint de health
curl http://localhost:8000/health

# testa gera√ß√£o de conte√∫do
curl -X POST http://localhost:8000/api/brief \
  -H "Content-Type: application/json" \
  -d '{"topic": "Teste", "target_audience": "Desenvolvedores", "tonality": "casual", "platforms": ["instagram"], "duration": 30}'
```

## üîç Troubleshooting

### Problemas Comuns

**Ollama n√£o responde**
```bash
# verifica se modelo foi baixado
docker exec multi_agentes_ollama ollama list

# reinicia servi√ßo
docker-compose restart ollama
```

**API retorna erro 500**
```bash
# verifica logs
docker logs multi_agentes_api

# verifica conectividade com Ollama
docker exec multi_agentes_api curl http://ollama:11434/api/tags
```

**ChromaDB com erro de permiss√£o**
```bash
# ajusta permiss√µes
sudo chown -R 1000:1000 ./chroma_db
```

### Performance

**Otimiza√ß√µes recomendadas:**
- Aumente RAM para 16GB+ se usar modelos maiores
- Use SSD para melhor I/O do ChromaDB
- Configure rate limiting adequado para sua carga
- Monitore uso de CPU durante gera√ß√£o

## üìù Estrutura do Projeto

```
‚îú‚îÄ‚îÄ agents.py          # Agentes CrewAI especializados
‚îú‚îÄ‚îÄ config.py          # Configura√ß√µes e prompts
‚îú‚îÄ‚îÄ main.py           # API FastAPI principal
‚îú‚îÄ‚îÄ memory.py         # Vector database e RAG
‚îú‚îÄ‚îÄ models.py         # Schemas Pydantic
‚îú‚îÄ‚îÄ docker-compose.yml # Orquestra√ß√£o completa
‚îú‚îÄ‚îÄ Dockerfile        # Container da API
‚îú‚îÄ‚îÄ nginx.conf        # Configura√ß√£o do proxy
‚îú‚îÄ‚îÄ prometheus.yml    # Configura√ß√£o de monitoramento
‚îî‚îÄ‚îÄ requirements.txt  # Depend√™ncias Python
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie branch para feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudan√ßas (`git commit -m 'adiciona nova funcionalidade'`)
4. Push para branch (`git push origin feature/nova-funcionalidade`)
5. Abra Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa MIT. Veja `LICENSE` para mais detalhes.